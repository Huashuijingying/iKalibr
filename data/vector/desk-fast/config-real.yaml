Configor:
  DataStream:
    # key: IMU topic, value: IMU type. Supported IMU types are:
    #   1.              SBG_IMU: https://github.com/SBG-Systems/sbg_ros_driver.git
    #   2.           SENSOR_IMU: gyro unit (rad/s), acce unit (m/s^2), https://docs.ros.org/en/noetic/api/sensor_msgs/html/msg/Imu.html
    #   3.         SENSOR_IMU_G: gyro unit (rad/s), acce unit (G)
    #   4.     SENSOR_IMU_G_NEG: gyro unit (rad/s), acce unit (-G)
    #   5.       SENSOR_IMU_DEG: gyro unit (deg/s), acce unit (m/s^2), https://docs.ros.org/en/noetic/api/sensor_msgs/html/msg/Imu.html
    #   6.     SENSOR_IMU_DEG_G: gyro unit (deg/s), acce unit (G)
    #   7. SENSOR_IMU_DEG_G_NEG: gyro unit (deg/s), acce unit (-G)
    IMUTopics:
      - key: "/imu/data"
        value:
          Type: "SENSOR_IMU"
          Intrinsics: "/home/csl/ros_ws/iKalibr/src/ikalibr/config/imu-intri.yaml"
          AcceWeight: 17.68
          GyroWeight: 57.66
    # key: radar topic, value: radar type. Supported radar types are:
    #   1.     AINSTEIN_RADAR: https://github.com/AinsteinAI/ainstein_radar.git
    #   2. AWR1843BOOST_RAW: https://github.com/Unsigned-Long/ti_mmwave_rospkg.git
    #   3. AWR1843BOOST_CUSTOM: https://github.com/Unsigned-Long/ti_mmwave_rospkg.git
    #   4.  POINTCLOUD2_POSV: 'sensor_msgs/PointCloud2' with point format: [x, y, z, velocity]
    #   5.  POINTCLOUD2_POSIV: 'sensor_msgs/PointCloud2' with point format: [x, y, z, intensity, velocity]
    #   6.  POINTCLOUD2_XRIO: 'sensor_msgs/PointCloud2' with x-RIO point format (see https://github.com/christopherdoer/rio.git)
    RadarTopics:
    #   1.        Velodyne LiDARs: VLP_16_PACKET, VLP_POINTS
    #   2.          Ouster LiDARs: OUSTER_POINTS
    #   3. Hesai Pandar XT LiDARs: PANDAR_XT_POINTS
    #   4.           Livox LiDARs: LIVOX_CUSTOM (the official 'xfer_format'=1, mid-360 and avia is recommend)
    LiDARTopics:
    # key: camera topic, value: camera type. Supported camera types:
    #   1. SENSOR_IMAGE_GS: https://docs.ros.org/en/noetic/api/sensor_msgs/html/msg/Image.html\n"
    #   2. SENSOR_IMAGE_RS_FIRST: first-row exposure, https://docs.ros.org/en/noetic/api/sensor_msgs/html/msg/Image.html\n"
    #   3. SENSOR_IMAGE_RS_MID: middle-row exposure, https://docs.ros.org/en/noetic/api/sensor_msgs/html/msg/Image.html\n"
    #   4. SENSOR_IMAGE_RS_LAST: last-row exposure, https://docs.ros.org/en/noetic/api/sensor_msgs/html/msg/Image.html\n"
    #   5. SENSOR_IMAGE_COMP_GS: https://docs.ros.org/en/noetic/api/sensor_msgs/html/msg/CompressedImage.html\n"
    #   6. SENSOR_IMAGE_COMP_RS_FIRST: first-row exposure, https://docs.ros.org/en/noetic/api/sensor_msgs/html/msg/CompressedImage.html\n"
    #   7. SENSOR_IMAGE_COMP_RS_MID: middle-row exposure, https://docs.ros.org/en/noetic/api/sensor_msgs/html/msg/CompressedImage.html\n"
    #   8. SENSOR_IMAGE_COMP_RS_LAST: last-row exposure, https://docs.ros.org/en/noetic/api/sensor_msgs/html/msg/CompressedImage.html\n"
    CameraTopics:
    #      - key: "/camera/left/image_mono_undistort"
    #        value:
    #          Type: "SENSOR_IMAGE_GS"
    #          Intrinsics: "/home/csl/ros_ws/iKalibr/src/ikalibr/data/vector/cam-left-intri-pinhole-brown.yaml"
    #          # 0.1 for 'LIN_VEL_SPLINE', and 50.0 for 'LIN_POS_SPLINE'
    #          Weight: 0.1
    #          TrackLengthMin: 5
    #          # 'LIN_POS_SPLINE' or 'LIN_VEL_SPLINE'
    #          ScaleSplineType: LIN_VEL_SPLINE
    #      - key: "/camera/right/image_mono_undistort"
    #        value:
    #          Type: "SENSOR_IMAGE_GS"
    #          Intrinsics: "/home/csl/ros_ws/iKalibr/src/ikalibr/data/vector/cam-right-intri-pinhole-brown.yaml"
    #          Weight: 50.0
    #          TrackLengthMin: 5
    #          # 'LIN_POS_SPLINE' or 'LIN_VEL_SPLINE'
    #          ScaleSplineType: LIN_POS_SPLINE
    # key: rgbd color image topic, value: camera type. Supported camera types are the same as the ones in 'CameraTopics'
    RGBDTopics:
    #      - key: "/camera/left/image_mono_undistort"
    #        value:
    #          Type: "SENSOR_IMAGE_GS"
    #          Intrinsics: "/home/csl/ros_ws/iKalibr/src/ikalibr/data/vector/cam-left-intri-pinhole-brown.yaml"
    #          # the depth map needs to correspond one-to-one with the pixels in the color image after undistorted.
    #          DepthTopic: "/camera/left/depth_image_undistort"
    #          # {real depth} = abs{DepthFactor} * {image depth}, if 'DepthFactor' is positive
    #          # {real depth} = abs{DepthFactor} / {image depth}, if 'DepthFactor' is negative (depth images are inverse ones)
    #          DepthFactor: 0.001
    #          # too large weight would lead to poor convergence
    #          Weight: 0.1
    #          TrackLengthMin: 3
    #      - key: "/camera/right/image_mono_undistort"
    #        value:
    #          Type: "SENSOR_IMAGE_GS"
    #          Intrinsics: "/home/csl/ros_ws/iKalibr/src/ikalibr/data/vector/cam-right-intri-pinhole-brown.yaml"
    #          # the depth map needs to correspond one-to-one with the pixels in the color image after undistorted.
    #          DepthTopic: "/camera/right/depth_image_undistort"
    #          # {real depth} = abs{DepthFactor} * {image depth}, if 'DepthFactor' is positive
    #          # {real depth} = abs{DepthFactor} / {image depth}, if 'DepthFactor' is negative (depth images are inverse ones)
    #          DepthFactor: 0.001
    #          Weight: 0.1
    #          TrackLengthMin: 3
    # key: event camera topic, value: event type. Supported event types:
    # 1. PROPHESEE_EVENT: https://github.com/prophesee-ai/prophesee_ros_wrapper.git
    EventTopics:
      - key: "/prophesee/left/events"
        value:
          Type: "PROPHESEE_EVENT"
          Intrinsics: "/home/csl/ros_ws/iKalibr/src/ikalibr/data/vector/event-left-intri-pinhole-brown.yaml"
          Weight: 0.1
    #      - key: "/prophesee/right/events"
    #        value:
    #          Type: "PROPHESEE_EVENT"
    #          Intrinsics: "/home/csl/ros_ws/iKalibr/src/ikalibr/data/vector/event-right-intri-pinhole-brown.yaml"
    #          Weight: 0.1
    ReferIMU: "/imu/data"
    BagPath: "/home/csl/dataset/vector/desk_fast/desk_fast1.synced.ei.bag"
    # the time piece: [BegTime, BegTime + Duration], unit: second(s)
    # if you want to use all time data for calibration, please set them to negative numbers
    # Note that the 'BegTime' here is measured from the start time of bag
    # and is not related to the timestamp of the data recorded in the package.
    BeginTime: 5
    Duration: 10
    OutputPath: "/home/csl/ros_ws/iKalibr/src/ikalibr/data/vector/desk-fast"
  Prior:
    GravityNorm: 9.79
    # priori about spatiotemporal parameters, given by corresponding config file path
    SpatTempPrioriPath: ""
    # if sensor are hardware-synchronized, you could choose to fix temporal parameters by setting this field to 'false'
    OptTemporalParams: true
    # the range where the time offsets would be optimized.
    # make sure this range contains the ground truth of time offsets
    # If you're not sure, make this field large, but this could lead to longer optimization time
    TimeOffsetPadding: 0.02
    # readout time padding for RS camera
    ReadoutTimePadding: 0.04
    # leaf size when down sample the map using 'pcl::VoxelGrid' filter
    # note that this field just for visualization, no connection with calibration
    # for outdoor, 0.1 is suggested, and for indoor: 0.05 is suggested
    MapDownSample: 0.05
    # the time distance of two neighbor control points, which determines the accuracy
    # of the representation of the B-splines. Smaller distance would lead to longer optimization time
    # common choices: from '0.01' to '0.10'
    KnotTimeDist:
      SO3Spline: 0.05
      ScaleSpline: 0.05
    # when lidar is involved in the calibration framework, the ndt odometer is employed to recover pose roughly
    NDTLiDAROdometer:
      # 0.5 for indoor case and 1.0 for outdoor case
      Resolution: 0.5
      KeyFrameDownSample: 0.1
    LiDARDataAssociate:
      # associate point and surfel when distance is less than this value
      PointToSurfelMax: 0.1
      # chose plane as a surfel for data association when planarity is larger than this value
      PlanarityMin: 0.6
  Preference:
    # whether using cuda to speed up when solving least-squares problems
    UseCudaInSolving: true
    # currently available output content:
    # ParamInEachIter, BSplines, LiDARMaps, VisualMaps, RadarMaps, HessianMat,
    # VisualLiDARCovisibility, VisualKinematics, ColorizedLiDARMap
    # AlignedInertialMes, VisualReprojErrors, RadarDopplerErrors, VisualOpticalFlowErrors
    # NONE, ALL
    Outputs:
      - NONE
    # supported data output format:
    # 1. JSON
    # 2. XML
    # 3. YAML
    # 4. BINARY (not recommended)
    OutputDataFormat: YAML
    # number of thread to use for solving, negative value means use all valid thread to perform solving
    ThreadsToUse: -1
    # scale of splines in viewer, you can also use 'a' and 'd' keys to zoom out and in splines in run time
    SplineScaleInViewer: 3.0
    # scale of coordinates in viewer, you can also use 's' and 'w' keys to zoom out and in coordinates in run time
    CoordSScaleInViewer: 0.3
